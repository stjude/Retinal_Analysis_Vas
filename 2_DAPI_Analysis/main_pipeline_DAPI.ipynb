{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16c6ed-0edf-42f1-93a4-89b60b7c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Data\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "\n",
    "# Architecture imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import List, Tuple\n",
    "import shutil\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "from skimage import exposure\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9582ce8-f1a4-481c-929f-57a787913298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is there\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU available for execution \")\n",
    "else:\n",
    "    print(\"GPU not available ! . Please check or proceed to execute in CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6559684-0b70-45c4-b7e4-1367d2e18358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "os.environ[\"nnUNet_raw\"] = \"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/DAPI/nnunet/nnUNet_raw\"\n",
    "os.environ[\"nnUNet_preprocessed\"] = \"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/DAPI/nnunet/nnUNet_preprocessed\"\n",
    "os.environ[\"nnUNet_results\"] = \"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/DAPI/nnunet/nnUNet_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a759405c-464f-4f0a-bc2c-260358bb48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(r\"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/Outputs_DL_CBI_9-20-23/3_input_subgroups/1\")\n",
    "output_path = r\"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/Outputs_DL_CBI_9-20-23/2_Full_execution_outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f8038-bc18-448e-8f05-05a4af23c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnunet details\n",
    "dataset_num=104\n",
    "#config=\"2d\"\n",
    "config=\"3d_fullres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b2090-f227-4665-b920-5d4938fef947",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_demand=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfe3f4-ec9e-4b3c-9bbd-3b8c701e796f",
   "metadata": {},
   "source": [
    "## Chunk the Image and Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c009355-3560-4cce-ad93-ea9f2e2f2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chuncks(volume, output_folder, tif_file,chunk_size=(128, 256, 256)):\n",
    "    # Calculate number of chunks in each dimension\n",
    "    chunks_z = int(np.ceil(volume.shape[0] / chunk_size[0]))\n",
    "    chunks_y = int(np.ceil(volume.shape[1] / chunk_size[1]))\n",
    "    chunks_x = int(np.ceil(volume.shape[2] / chunk_size[2]))\n",
    "    chunk_num=0\n",
    "\n",
    "    for z in range(chunks_z):\n",
    "        for y in range(chunks_y):\n",
    "            for x in range(chunks_x):\n",
    "                # Calculate chunk boundaries\n",
    "                z_start, z_end = z * chunk_size[0], min((z + 1) * chunk_size[0], volume.shape[0])\n",
    "                y_start, y_end = y * chunk_size[1], min((y + 1) * chunk_size[1], volume.shape[1])\n",
    "                x_start, x_end = x * chunk_size[2], min((x + 1) * chunk_size[2], volume.shape[2])\n",
    "\n",
    "                # Extract chunks\n",
    "                volume_chunk = volume[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "               \n",
    "                # Pad chunks if necessary\n",
    "                if volume_chunk.shape != chunk_size:\n",
    "                    volume_chunk = np.pad(volume_chunk, \n",
    "                                          ((0, chunk_size[0] - volume_chunk.shape[0]), \n",
    "                                           (0, chunk_size[1] - volume_chunk.shape[1]), \n",
    "                                           (0, chunk_size[2] - volume_chunk.shape[2])),\n",
    "                                          mode='constant')\n",
    "\n",
    "                # Save chunks\n",
    "                chunk_name = f\"{tif_file[:-4]}_z{z}_y{y}_x{x}_{chunk_num:03}_0000.tif\"\n",
    "                tifffile.imwrite(output_folder / chunk_name, volume_chunk)\n",
    "                chunk_num+=1\n",
    "               \n",
    "    print(\"chunks created ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec747e5-9ec7-4b63-b70d-22a0938c9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume_bicubic(volume, target_size=(256, 819)):\n",
    "    \"\"\"\n",
    "    Performs bicubic interpolation on a 3D volume array to resize x and y dimensions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    volume : numpy.ndarray\n",
    "        Input 3D volume with shape (z, y, x)\n",
    "    target_size : tuple\n",
    "        Desired output size for (y, x) dimensions, default is (256, 819)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Resized volume with shape (z, 256, 819)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get current dimensions\n",
    "    z_dim, y_dim, x_dim = volume.shape\n",
    "    \n",
    "    # Calculate zoom factors for each dimension\n",
    "    z_factor = 1.0  # Keep z dimension unchanged\n",
    "    y_factor = target_size[0] / y_dim\n",
    "    x_factor = target_size[1] / x_dim\n",
    "    \n",
    "    # Perform bicubic interpolation\n",
    "    # order=3 specifies bicubic interpolation\n",
    "    resized_volume = zoom(volume, (z_factor, y_factor, x_factor), order=3)\n",
    "    \n",
    "    return resized_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b0588-a337-47a2-94ab-a7ef99dbfad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_label_volume(label_volume, original_shape):\n",
    "    \"\"\"\n",
    "    Resizes a label volume back to its original dimensions using nearest neighbor interpolation\n",
    "    to preserve label values.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    label_volume : numpy.ndarray\n",
    "        Input label volume with shape (z, 256, 819)\n",
    "    original_shape : tuple\n",
    "        Original shape to restore to (z, y, x)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Restored label volume with original shape\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get current dimensions\n",
    "    z_dim, y_dim, x_dim = label_volume.shape\n",
    "    \n",
    "    # Calculate zoom factors for each dimension\n",
    "    #z_factor = original_shape[0] / z_dim\n",
    "    z_factor = 1\n",
    "    y_factor = original_shape[1] / y_dim\n",
    "    x_factor = original_shape[2] / x_dim\n",
    "    \n",
    "    # Use nearest neighbor interpolation (order=0) to preserve label values\n",
    "    restored_volume = zoom(label_volume, (z_factor, y_factor, x_factor), order=0)\n",
    "    \n",
    "    return restored_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6fc748-fcfe-42ca-98e3-6c93337c5d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe_3d(volume, kernel_size=(8, 8), clip_limit=0.01, nbins=256):\n",
    "    \"\"\"\n",
    "    Applies Contrast Limited Adaptive Histogram Equalization (CLAHE) to a 3D volume\n",
    "    slice by slice along the z-axis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    volume : numpy.ndarray\n",
    "        Input 3D volume with shape (z, y, x)\n",
    "    kernel_size : tuple\n",
    "        Size of kernel for CLAHE in (y, x) dimensions, default is (8, 8)\n",
    "    clip_limit : float\n",
    "        Clipping limit for CLAHE, normalized between 0 and 1\n",
    "    nbins : int\n",
    "        Number of bins for histogram, default is 256\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        CLAHE processed volume with same shape as input\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if volume.ndim != 3:\n",
    "        raise ValueError(\"Input volume must be 3D\")\n",
    "        \n",
    "    # Convert to float and normalize to [0, 1] if not already\n",
    "    if volume.dtype != np.float32 and volume.dtype != np.float64:\n",
    "        volume_norm = volume.astype(float)\n",
    "        if volume_norm.max() > 1.0:\n",
    "            volume_norm = (volume_norm - volume_norm.min()) / (volume_norm.max() - volume_norm.min())\n",
    "    else:\n",
    "        volume_norm = volume.copy()\n",
    "    \n",
    "    # Initialize CLAHE object\n",
    "    clahe = exposure.equalize_adapthist\n",
    "    \n",
    "    # Process each slice\n",
    "    processed_volume = np.zeros_like(volume_norm)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for z in range(volume.shape[0]):\n",
    "            processed_volume[z] = clahe(\n",
    "                volume_norm[z],\n",
    "                kernel_size=kernel_size,\n",
    "                clip_limit=clip_limit,\n",
    "                nbins=nbins\n",
    "            )\n",
    "    \n",
    "    return processed_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c40b2-7e06-4e13-9a99-eae5ffa862c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xz_to_xy(volume):\n",
    "    return np.transpose(volume, (1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857c965-402a-49de-af0e-af49468649b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_volume(chunks_folder, output_folder, final_shape, chunk_size=(128, 256, 256)):\n",
    "    chunks_folder = Path(chunks_folder)\n",
    "    output_folder = Path(output_folder)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Group chunks by original filename\n",
    "    chunk_groups = {}\n",
    "    for chunk_file in chunks_folder.glob(\"*.tif\"):\n",
    "        # Parse chunk file name based on the new pattern\n",
    "        original_name, coords = chunk_file.stem.rsplit('_z', 1)\n",
    "        z, yx_chunknum = coords.split('_y')\n",
    "        y, x_chunknum = yx_chunknum.split('_x')\n",
    "        x, chunk_num = x_chunknum.split('_')\n",
    "        \n",
    "        # Convert coordinates and chunk_num to integers\n",
    "        z, y, x = int(z), int(y), int(x)\n",
    "        \n",
    "        # Group chunks by original file name\n",
    "        if original_name not in chunk_groups:\n",
    "            chunk_groups[original_name] = []\n",
    "        chunk_groups[original_name].append((z, y, x, chunk_file))\n",
    "\n",
    "    for original_name, chunks in chunk_groups.items():\n",
    "        # Determine the shape of the padded volume\n",
    "        max_z = max(chunk[0] for chunk in chunks) + 1\n",
    "        max_y = max(chunk[1] for chunk in chunks) + 1\n",
    "        max_x = max(chunk[2] for chunk in chunks) + 1\n",
    "\n",
    "        # Initialize the reconstructed volume (padded)\n",
    "        padded_shape = (\n",
    "            max_z * chunk_size[0],\n",
    "            max_y * chunk_size[1],\n",
    "            max_x * chunk_size[2]\n",
    "        )\n",
    "        reconstructed_volume = np.zeros(padded_shape, dtype=np.float32)\n",
    "\n",
    "        # Fill the reconstructed volume with chunks\n",
    "        for z, y, x, chunk_file in chunks:\n",
    "            chunk = tifffile.imread(chunk_file)\n",
    "            reconstructed_volume[\n",
    "                z * chunk_size[0] : (z + 1) * chunk_size[0],\n",
    "                y * chunk_size[1] : (y + 1) * chunk_size[1],\n",
    "                x * chunk_size[2] : (x + 1) * chunk_size[2]\n",
    "            ] = chunk\n",
    "\n",
    "        # Crop the reconstructed volume to the final shape\n",
    "        #final_volume = reconstructed_volume[:final_shape[0], :final_shape[1], :final_shape[2]]\n",
    "        final_volume = reconstructed_volume\n",
    "\n",
    "        # Save the reconstruction\n",
    "        output_file = output_folder / f\"{original_name}_reconstructed_original_before_shape_adjustment.tif\"\n",
    "        tifffile.imwrite(output_file, final_volume)\n",
    "\n",
    "        # Adjust the size of the final label\n",
    "        restored_final_volume = restore_label_volume(final_volume, final_shape)\n",
    "\n",
    "        # Unnecessary step - at this stage final shape should be the shaoe if restored_final_volume - but still clipping\n",
    "        restored_final_volume = restored_final_volume[:final_shape[0], :final_shape[1], :final_shape[2]]\n",
    "\n",
    "        # Save the reconstructed and cropped volume\n",
    "        output_file = output_folder / f\"{original_name}_reconstructed.tif\"\n",
    "        tifffile.imwrite(output_file, restored_final_volume)\n",
    "\n",
    "        # Transpose from xz to xy and save\n",
    "        xy_final_volume = convert_xz_to_xy(restored_final_volume)\n",
    "        xy_output_file = output_folder / f\"{original_name}_reconstructed_xy.tif\"\n",
    "        tifffile.imwrite(xy_output_file, xy_final_volume)\n",
    "        \n",
    "\n",
    "    print(\"Reconstruction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676afac-cebd-4e1e-8134-cca9733c8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nnunet(input_path, output_path, dataset_num, config):\n",
    "    # Create output directory\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Run command\n",
    "    cmd = [\n",
    "        \"nnUNetv2_predict\",\n",
    "        \"-i\", str(input_path),\n",
    "        \"-o\", str(output_path),\n",
    "        \"-d\", str(dataset_num),\n",
    "        \"-c\", config,\n",
    "        \"--save_probabilities\"\n",
    "    ]\n",
    "\n",
    "    result = ' '.join(cmd)\n",
    "    print(\"command is\", result)\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(cmd, check=True, text=True)\n",
    "        print(\"Prediction completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d4c68-f928-40f0-a920-5ba1128a615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nnunet_ondemand(input_path, output_path, dataset_num, config):\n",
    "    # Create output directory\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Run command\n",
    "    cmd = [\n",
    "        \"nnUNetv2_predict\",\n",
    "        \"-i\", str(input_path),\n",
    "        \"-o\", str(output_path),\n",
    "        \"-d\", str(dataset_num),\n",
    "        \"-c\", config,\n",
    "        \"--save_probabilities\"\n",
    "    ]\n",
    "\n",
    "    cmd = [\"conda\", \"run\", \"-p\", \"/research/sharedresources/cbi/public/conda_envs/nnunet\"] + cmd\n",
    "\n",
    "    result = ' '.join(cmd)\n",
    "    print(\"command is\", result)\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(cmd, check=True, text=True)\n",
    "        print(\"Prediction completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04aa16f-46fb-46cb-935d-83e0699b3b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_for_single_volume(file_path,output_path):\n",
    "    print(\"Executing for \",file_path.stem)\n",
    "\n",
    "    # Read the volume\n",
    "    volume = tifffile.imread(file_path)\n",
    "\n",
    "    # Restructure the input volume to match nn input shape\n",
    "    resized_volume = resize_volume_bicubic(volume, target_size=(256, 819))\n",
    "\n",
    "    print(\"Preprocessing with clahe\")\n",
    "    # Apply clahe \n",
    "    resized_preprocessed_volume = apply_clahe_3d(resized_volume)\n",
    "    \n",
    "    # Make Chuncks\n",
    "    chuncked_volume_output = Path(output_path) / (str(file_path.stem) + \"_chunks\")\n",
    "    chuncked_volume_output.mkdir(parents=True, exist_ok=True)    \n",
    "    #make_chuncks(volume, chuncked_volume_output, file_path.name,chunk_size=(128, 256, 256))\n",
    "    make_chuncks(resized_preprocessed_volume, chuncked_volume_output, file_path.name,chunk_size=(128, 256, 819))\n",
    "    \n",
    "    # Create Segmentation\n",
    "    model_outputs = Path(output_path) / (str(file_path.stem) + \"_segmentations\")\n",
    "    model_outputs.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Execute nn unet - change here if you running on downsampled image --- for faster execution remove downsampling in future\n",
    "    if on_demand:\n",
    "        run_nnunet_ondemand(chuncked_volume_output, model_outputs, dataset_num, config)\n",
    "        #print(\"\")\n",
    "    else:\n",
    "        run_nnunet(chuncked_volume_output, model_outputs, dataset_num, config)\n",
    "    \n",
    "    # Reconstruct\n",
    "    #reconstruct_volume(model_outputs_upsampled, output_path, volume.shape, chunk_size=(128, 256, 256))\n",
    "    #reconstruct_volume(model_outputs, output_path, volume.shape, chunk_size=(128, 256, 256))\n",
    "    reconstruct_volume(model_outputs, output_path, volume.shape, chunk_size=(128, 256, 819))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd59f8-a179-4e2a-98e7-e4e9a4fcda14",
   "metadata": {},
   "source": [
    "## Get all valid isotropic DAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965208e7-d063-4f4a-93d6-66148b8c154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dapi_paths(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process directories to find DAPI XZ images and create corresponding result folders.\n",
    "    Skip folders that already contain processed results (C4-DAPI-XZ_reconstructed.tif).\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Path to the input directory containing processed images\n",
    "        output_dir (str): Path to create DAPI results folders\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[str], List[str]]: Lists of (input DAPI paths, output result folder paths)\n",
    "    \"\"\"\n",
    "    # Initialize lists to store paths\n",
    "    dapi_xz_paths = []\n",
    "    dapi_result_paths = []\n",
    "    \n",
    "    # Convert to Path objects for easier handling\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        # Convert current root to Path object\n",
    "        root_path = Path(root)\n",
    "        \n",
    "        # Check if we're in an isotropic_image folder\n",
    "        if root_path.name == \"isotropic_image\":\n",
    "            # Look for C4-DAPI-XZ.tif in files\n",
    "            if \"C4-DAPI-XZ.tif\" in files:\n",
    "                # Get the full path to the DAPI XZ image\n",
    "                dapi_path = root_path / \"C4-DAPI-XZ.tif\"\n",
    "                \n",
    "                # Get the series folder name (parent of isotropic_image)\n",
    "                series_folder = root_path.parent.name\n",
    "                \n",
    "                # Create corresponding output folder structure\n",
    "                result_folder = output_path / series_folder / \"DAPI_results\"\n",
    "                result_folder.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # Check if reconstructed file already exists\n",
    "                reconstructed_file = result_folder / \"C4-DAPI-XZ_reconstructed.tif\"\n",
    "                if reconstructed_file.exists():\n",
    "                    print(f\"Skipping {dapi_path} - reconstructed file already exists\")\n",
    "                    continue\n",
    "                \n",
    "                # Add paths to lists\n",
    "                dapi_xz_paths.append(str(dapi_path))\n",
    "                dapi_result_paths.append(str(result_folder))\n",
    "                \n",
    "                print(f\"Found DAPI XZ image: {dapi_path}\")\n",
    "                print(f\"Created results folder: {result_folder}\")\n",
    "    \n",
    "    return dapi_xz_paths, dapi_result_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d04db9-2aa9-4568-bbf3-fb3f508e7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dapi_paths, result_paths = process_dapi_paths(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cae0e0-7181-4518-8de5-23944e892b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dapi_paths))\n",
    "print(dapi_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884826f-a155-42a4-b08b-569348666acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dapi_input_file, result_output_directory in zip(dapi_paths, result_paths):\n",
    "    print(\"Executing DAPI - model segmentation for :\")\n",
    "    print(dapi_input_file)\n",
    "    # Execute for single volume\n",
    "    execute_for_single_volume(Path(dapi_input_file),result_output_directory)\n",
    "print(\"Processing complete !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aed7c5-35ec-4ebc-b947-53cd78d49893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff432e46-19ee-40b5-9b48-cfbaf00db6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7cc63-957b-428d-a365-8fb5b8ed4dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05100878-a69a-4820-a3a6-7a2dd0e0b5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
