{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3e88d-ce11-4085-9aab-cea67bb25e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "import cc3d\n",
    "from scipy import ndimage\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8f966-aec1-4d6d-b0eb-47a6238cb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/Outputs_DL_CBI_9-20-23/2_Full_execution_outputs/\"\n",
    "path_to_look_at_to_run_onlyfor_those= r\"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/Outputs_DL_CBI_9-20-23/3_input_subgroups/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caa630-685d-49ac-91e8-43af93e2618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_largest_component(volume, label, min_volume_threshold):\n",
    "    \"\"\"\n",
    "    Extract the largest connected component of a given label using cc3d.\n",
    "    Set to 0 if below volume threshold.\n",
    "    \"\"\"\n",
    "    label_mask = (volume == label)\n",
    "    labels_out, N = cc3d.connected_components(label_mask, return_N=True)\n",
    "    \n",
    "    if N == 0:\n",
    "        return volume\n",
    "    \n",
    "    stats = cc3d.statistics(labels_out)\n",
    "    component_sizes = [stats['voxel_counts'][i] for i in range(1, N + 1)]\n",
    "    \n",
    "    output = volume.copy()\n",
    "    output[volume == label] = 0\n",
    "    \n",
    "    if len(component_sizes) > 0:\n",
    "        largest_size = max(component_sizes)\n",
    "        if largest_size >= min_volume_threshold:\n",
    "            largest_component_idx = np.argmax(component_sizes) + 1\n",
    "            output[labels_out == largest_component_idx] = label\n",
    "            \n",
    "    return output\n",
    "\n",
    "def fill_horizontal_zeros(slice_2d):\n",
    "    \"\"\"\n",
    "    Fill zero islands in a 2D slice using horizontal neighbors based on midpoint.\n",
    "    \"\"\"\n",
    "    filled_slice = slice_2d.copy()\n",
    "    y_dim, x_dim = slice_2d.shape\n",
    "    mid_point = x_dim // 2\n",
    "    \n",
    "    for y in range(y_dim):\n",
    "        row = slice_2d[y]\n",
    "        zero_positions = np.where(row == 0)[0]\n",
    "        \n",
    "        for x in zero_positions:\n",
    "            left_values = row[:x]\n",
    "            right_values = row[x+1:]\n",
    "            \n",
    "            left_labels = left_values[left_values != 0]\n",
    "            right_labels = right_values[right_values != 0]\n",
    "            \n",
    "            if x >= mid_point:  # In right half of image\n",
    "                if len(left_labels) > 0:\n",
    "                    filled_slice[y, x] = left_labels[-1]\n",
    "                elif len(right_labels) > 0:\n",
    "                    filled_slice[y, x] = right_labels[0]\n",
    "            else:  # In left half of image\n",
    "                if len(right_labels) > 0:\n",
    "                    filled_slice[y, x] = right_labels[0]\n",
    "                elif len(left_labels) > 0:\n",
    "                    filled_slice[y, x] = left_labels[-1]\n",
    "    \n",
    "    return filled_slice\n",
    "\n",
    "def fill_vertical_zeros(slice_2d):\n",
    "    \"\"\"\n",
    "    Fill remaining zeros in each column with nearest non-zero value from above.\n",
    "    \"\"\"\n",
    "    filled_slice = slice_2d.copy()\n",
    "    y_dim, x_dim = slice_2d.shape\n",
    "    \n",
    "    # Process each column\n",
    "    for x in range(x_dim):\n",
    "        # Find zero positions in this column\n",
    "        column = slice_2d[:, x]\n",
    "        zero_positions = np.where(column == 0)[0]\n",
    "        \n",
    "        for y in zero_positions:\n",
    "            # Look at values above this position\n",
    "            values_above = column[:y]\n",
    "            non_zero_above = values_above[values_above != 0]\n",
    "            \n",
    "            if len(non_zero_above) > 0:\n",
    "                # Fill with nearest non-zero value from above\n",
    "                filled_slice[y, x] = non_zero_above[-1]\n",
    "    \n",
    "    return filled_slice\n",
    "\n",
    "def reverse_DAPI_cleanup(volume, min_volume_thresholds=None):\n",
    "    \"\"\"\n",
    "    Clean up DAPI volume starting from highest label, \n",
    "    keeping only largest components above threshold,\n",
    "    then fill zero islands horizontally and vertically.\n",
    "    \"\"\"\n",
    "    if min_volume_thresholds is None:\n",
    "        min_volume_thresholds = {label: 90000 for label in range(1, 8)}\n",
    "    \n",
    "    # Process labels in reverse order\n",
    "    cleaned_volume = volume.copy()\n",
    "    for label in range(7, 0, -1):\n",
    "        print(f\"Processing label {label}...\")\n",
    "        cleaned_volume = extract_largest_component(\n",
    "            cleaned_volume, \n",
    "            label, \n",
    "            min_volume_thresholds[label]\n",
    "        )\n",
    "    \n",
    "    print(\"Filling zero islands horizontally...\")\n",
    "    z_dim, y_dim, x_dim = cleaned_volume.shape\n",
    "    for z in range(z_dim):\n",
    "        if z % 10 == 0:\n",
    "            print(f\"Processing slice {z}/{z_dim}\")\n",
    "        cleaned_volume[z] = fill_horizontal_zeros(cleaned_volume[z])\n",
    "    \n",
    "    print(\"Filling remaining zeros vertically...\")\n",
    "    for z in range(z_dim):\n",
    "        if z % 10 == 0:\n",
    "            print(f\"Processing slice {z}/{z_dim}\")\n",
    "        cleaned_volume[z] = fill_vertical_zeros(cleaned_volume[z])\n",
    "    \n",
    "    return cleaned_volume\n",
    "\n",
    "def check_volume_stats(volume):\n",
    "    \"\"\"\n",
    "    Print statistics about label volumes.\n",
    "    \"\"\"\n",
    "    unique_labels, counts = np.unique(volume, return_counts=True)\n",
    "    total_voxels = volume.size\n",
    "    \n",
    "    print(\"\\nLabel Statistics:\")\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        percentage = (count / total_voxels) * 100\n",
    "        print(f\"Label {label}: {count:,} voxels ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd629887-74a7-4727-ad7f-82e17ab74c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dapi_cleanup_paths(input_dir, path_to_look_at_to_run_onlyfor_those):\n",
    "    # Initialize empty lists for input and result paths\n",
    "    dapi_cleanup_input_paths = []\n",
    "    dapi_cleanup_result_paths = []\n",
    "    dapi_xy_corrected_results_paths = []\n",
    "    \n",
    "    # Convert input directory to Path object\n",
    "    input_path = Path(input_dir)\n",
    "    lookup_path = Path(path_to_look_at_to_run_onlyfor_those)\n",
    "    \n",
    "    # Get list of folder names from the lookup path\n",
    "    folders_to_process = set()\n",
    "    for item in lookup_path.iterdir():\n",
    "        if item.is_dir():\n",
    "            folders_to_process.add(item.name)\n",
    "    \n",
    "    print(\"\\nFolders found in lookup path:\", folders_to_process)\n",
    "    \n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        root_path = Path(root)\n",
    "        \n",
    "        # Check if this is a DAPI_results directory\n",
    "        if root_path.name == \"DAPI_results\":\n",
    "            parent_folder_name = root_path.parent.name\n",
    "            \n",
    "            # Check if parent folder name is in our target list\n",
    "            if parent_folder_name not in folders_to_process:\n",
    "                #print(f\"\\nSkipped - Folder not in lookup list: {parent_folder_name}\")\n",
    "                #print(f\"Path: {root_path}\")\n",
    "                continue\n",
    "                \n",
    "            # Check files existence\n",
    "            has_original = \"C4-DAPI-XZ_reconstructed.tif\" in files\n",
    "            has_cleaned = \"C4-DAPI-XZ_reconstructed_cleaned.tif\" in files\n",
    "            \n",
    "            if not has_original:\n",
    "                #print(f\"\\nSkipped - Original file missing in: {parent_folder_name}\")\n",
    "                #print(f\"Path: {root_path}\")\n",
    "                continue\n",
    "                \n",
    "            if has_cleaned:\n",
    "                print(f\"\\nSkipped - Cleaned file already exists in: {parent_folder_name}\")\n",
    "                print(f\"Path: {root_path}\")\n",
    "                continue\n",
    "            \n",
    "            # If we get here, we're processing this path\n",
    "            #print(f\"\\nProcessing: {parent_folder_name}\")\n",
    "            #print(f\"Path: {root_path}\")\n",
    "            \n",
    "            # Create full path for input file\n",
    "            input_file_path = root_path / \"C4-DAPI-XZ_reconstructed.tif\"\n",
    "            # Create full path for output file in the same folder\n",
    "            result_file_path = root_path / \"C4-DAPI-XZ_reconstructed_cleaned.tif\"\n",
    "            # xy correction\n",
    "            xy_corrected_path = root_path / \"C4-DAPI-XZ_reconstructed_cleaned_xy.tif\"\n",
    "            \n",
    "            # Append paths to respective lists\n",
    "            dapi_cleanup_input_paths.append(str(input_file_path))\n",
    "            dapi_cleanup_result_paths.append(str(result_file_path))\n",
    "            dapi_xy_corrected_results_paths.append(str(xy_corrected_path))\n",
    "    \n",
    "    # Print summary at the end\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total paths to process: {len(dapi_cleanup_input_paths)}\")\n",
    "    \n",
    "    return dapi_cleanup_input_paths, dapi_cleanup_result_paths, dapi_xy_corrected_results_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3553bfc-e30c-466c-9149-d5c0d9af5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dapi_cleanup_input_paths, dapi_cleanup_result_paths, dapi_xy_corrected_results_paths = process_dapi_cleanup_paths(input_path,path_to_look_at_to_run_onlyfor_those)\n",
    "print(dapi_cleanup_input_paths)\n",
    "print(len(dapi_cleanup_input_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84837b-df22-4495-a062-499c6e9839d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xz_to_xy(volume):\n",
    "    return np.transpose(volume, (1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34266188-fc32-4ea1-90e4-d7f1010ac5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tif_file_path, results_path, xy_corrected_results_path in zip(dapi_cleanup_input_paths, dapi_cleanup_result_paths, dapi_xy_corrected_results_paths):\n",
    "    volume = tifffile.imread(tif_file_path)\n",
    "    print(\"volume reading complete ...\")\n",
    "    cleaned_volume = reverse_DAPI_cleanup(volume)\n",
    "    print(\"Cleanup successful\")\n",
    "    tifffile.imwrite(results_path, cleaned_volume)\n",
    "    xy_final_volume = convert_xz_to_xy(cleaned_volume)\n",
    "    tifffile.imwrite(xy_corrected_results_path, xy_final_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fe334-87f4-4cf2-b4c9-c02a52f09fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67120237-3746-4458-86d4-19aa803820a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf2b20-6d24-4621-b327-f7acc407f205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda911a-f6fa-42b2-b32c-e498b581cbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51cf227f-d173-4ca9-8223-e1f7d6d48353",
   "metadata": {},
   "source": [
    "## Single Sample Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53e0d4-e2ce-40a5-8022-c06622cee5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_path = \"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/Outputs_DL6-14-24-21_FM_SickleCell/3_experiments/dapi_Experiment/C-TxRBCX706F_AcquisitionBlock1_series4/DAPI_results/C4-DAPI-XZ_reconstructed.tif\"\n",
    "#output_path = \"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/Outputs_DL6-14-24-21_FM_SickleCell/3_experiments/dapi_Experiment/C-TxRBCX706F_AcquisitionBlock1_series4/DAPI_results/cleaned_volume_3.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94d5a2-c715-4b07-be5c-31b9309b25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import tifffile\n",
    "volume = tifffile.imread(input_path)\n",
    "print(\"volume reading complete ...\")\n",
    "#cleaned_volume = DAPI_cleanup(volume)\n",
    "cleaned_volume = reverse_DAPI_cleanup(volume)\n",
    "print(\"Cleanup successful\")\n",
    "tifffile.imwrite(output_path, cleaned_volume)\n",
    "print(f\"Cleaned volume saved to {output_path}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2ddc7-b9c3-4c54-9f1b-36eb32e4b1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861552e-09ed-48e7-88b7-9ba6c0ec41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "\n",
    "def check_dapi_files(input_path):\n",
    "    # List to store paths with incorrect shapes\n",
    "    incorrect_shape_paths = []\n",
    "    \n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        # Convert current root to Path object\n",
    "        root_path = Path(root)\n",
    "        \n",
    "        # Check if we're in an isotropic_image folder\n",
    "        if root_path.name == \"isotropic_image\":\n",
    "            # Look for C4-DAPI-XZ.tif in files\n",
    "            if \"C4-DAPI-XZ.tif\" in files:\n",
    "                # Get the full path to the DAPI XZ image\n",
    "                dapi_path = root_path / \"C4-DAPI-XZ.tif\"\n",
    "                \n",
    "                try:\n",
    "                    # Read the TIFF file\n",
    "                    with tifffile.TiffFile(dapi_path) as tif:\n",
    "                        image = tif.asarray()\n",
    "                        \n",
    "                    # Check the shape\n",
    "                    # image shape should be (819, z, 819) for (x,z,y)\n",
    "                    if image.shape[0] != 819 or image.shape[2] != 819:\n",
    "                        incorrect_shape_paths.append(str(dapi_path))\n",
    "                        print(f\"Incorrect shape found in {dapi_path}\")\n",
    "                        print(f\"Shape is {image.shape}, expected (819, z, 819)\")\n",
    "                        print(f\"Current dimensions: x={image.shape[0]}, z={image.shape[1]}, y={image.shape[2]}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {dapi_path}: {str(e)}\")\n",
    "    \n",
    "    # Print summary of findings\n",
    "    if incorrect_shape_paths:\n",
    "        print(\"\\nFiles with incorrect shapes:\")\n",
    "        for path in incorrect_shape_paths:\n",
    "            print(path)\n",
    "    else:\n",
    "        print(\"\\nAll found files have correct shape (819, z, 819)\")\n",
    "    \n",
    "    return incorrect_shape_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960ff30-18d6-48bf-b7a2-54c00af5f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dapi_files(\"/research/sharedresources/cbi/data_exchange/dyergrp/retinal_degeneration/Version_4_underdev/Outputs_DL6-14-24-21_FM_SickleCell_Controls/1_preprocessing_and_isotropization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37060e1-3e1e-437a-a87b-0ec2fd785b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
