{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16c6ed-0edf-42f1-93a4-89b60b7c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.morphology import binary_erosion, skeletonize, label\n",
    "from skimage import draw\n",
    "from skan import Skeleton, summarize\n",
    "import scipy.ndimage as ndi\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "from skan.csr import skeleton_to_csgraph\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.segmentation import watershed\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4e5c8-4963-4ccf-b1a8-a030d57c1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(r\"sample_test_Data/Input\")\n",
    "output_path = r\"sample_test_Data/Output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f121b9",
   "metadata": {},
   "source": [
    "## Auxilliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69c415-7a67-40c3-a20c-dfd6f07ba27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temp_dir(directory):\n",
    "    '''\n",
    "    Create a temporary directory if it does not exist and clear it if it does.\n",
    "    '''\n",
    "    # Check if the directory already exists\n",
    "    if not os.path.exists(directory):\n",
    "        # Create the directory\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "        print(f\"Clearing the directory...\")\n",
    "        # Clearing the directory for the next run\n",
    "        for filename in os.listdir(directory):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    directory.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def create_dir(directory):\n",
    "    '''\n",
    "    Create a temporary directory if it does not exist and clear it if it does.\n",
    "    '''\n",
    "    # Check if the directory already exists\n",
    "    if not os.path.exists(directory):\n",
    "        # Create the directory\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fdd8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for the computation of the number of bifurcations and end points\n",
    "def branching_points(branch_data):\n",
    "    branch_points=0\n",
    "    end_points=0\n",
    "    node_origin = branch_data['node-id-src'].values.tolist()\n",
    "    node_destination = branch_data['node-id-dst'].values.tolist()\n",
    "    all_nodes = node_origin + node_destination\n",
    "    aux_list = np.array(all_nodes)\n",
    "    bpoints_id = []\n",
    "    epoints_id = []\n",
    "    for element in np.unique(aux_list):\n",
    "        occur = all_nodes.count(element)\n",
    "        if occur>=3:\n",
    "            branch_points=branch_points+1\n",
    "            bpoints_id.append(element)\n",
    "        elif occur==1:\n",
    "            end_points=end_points+1\n",
    "            epoints_id.append(element)\n",
    "    return branch_points, bpoints_id, end_points, epoints_id\n",
    "\n",
    "\n",
    "def radius_3d_main(skeleton, branch_data, mask, boundary):\n",
    "    pixel_graph, coordinates_ = skeleton_to_csgraph(skeleton, spacing=[1,1,1])\n",
    "    dist_matrix, predecessors = shortest_path(pixel_graph, directed=True, indices=branch_data['node-id-src'].to_numpy(), return_predecessors=True)\n",
    "    #dist_matrix has size (#sourceids as in len(branch_data['node-id-src']), #all nodes in the skeleton)\n",
    "    \n",
    "    ## iterate through each branch and check the direction\n",
    "    all_major = []\n",
    "    all_minor = []\n",
    "    all_radii = []\n",
    "    all_paths = []\n",
    "    avg_branch_radii = []\n",
    "    avg_branch_minor_axis = []\n",
    "    avg_branch_major_axis = []\n",
    "    all_directions_units = []\n",
    "\n",
    "\n",
    "    for i in range(len(branch_data)):\n",
    "        \n",
    "        #node indices (i is the node-id-src, because it was used before to compute dist_matrix and predecessors)\n",
    "        b =  int(branch_data.iloc[i]['node-id-dst']) \n",
    "\n",
    "        # Check if there is a path between the two nodes (a and b)\n",
    "        if np.isinf(dist_matrix[i, b]):\n",
    "            print(\"No path exists between node a and node b.\")\n",
    "            all_paths.append([])\n",
    "            avg_branch_radii.append(0)\n",
    "            continue\n",
    "        else:\n",
    "            # Reconstruct the path from a to b\n",
    "            path = [(coordinates_[0][b], coordinates_[1][b], coordinates_[2][b])]\n",
    "            b = predecessors[i, b]\n",
    "            while b >= 0:\n",
    "                path.insert(0, (coordinates_[0][b], coordinates_[1][b], coordinates_[2][b]))\n",
    "                b = predecessors[i, b]\n",
    "\n",
    "            path = np.asarray(path)\n",
    "\n",
    "            #compute the direction of the branch\n",
    "            delta_x = (branch_data.iloc[i]['image-coord-src-0'])-(branch_data.iloc[i]['image-coord-dst-0'])\n",
    "            delta_y = (branch_data.iloc[i]['image-coord-src-1'])-(branch_data.iloc[i]['image-coord-dst-1'])\n",
    "            delta_z = (branch_data.iloc[i]['image-coord-src-2'])-(branch_data.iloc[i]['image-coord-dst-2'])\n",
    "\n",
    "            direction_unit = np.asarray([delta_x, delta_y, delta_z])\n",
    "            direction_unit = direction_unit / np.linalg.norm(direction_unit)\n",
    "            all_directions_units.append(direction_unit)\n",
    "            \n",
    "            major_axes, minor_axes, radii = compute_radii_aux(path, mask, boundary, direction_unit)\n",
    "            # print(f\"Radii {i}: {radii}\")\n",
    "            all_major = all_major + major_axes\n",
    "            all_minor = all_minor + minor_axes\n",
    "            all_radii = all_radii + radii\n",
    "            all_paths.append(path)\n",
    "\n",
    "            if radii:\n",
    "                avg_branch_radii.append(np.mean(radii))\n",
    "                avg_branch_minor_axis.append(np.mean(minor_axes))\n",
    "                avg_branch_major_axis.append(np.mean(major_axes))\n",
    "            else:\n",
    "                avg_branch_radii.append(0)\n",
    "                avg_branch_minor_axis.append(0)\n",
    "                avg_branch_major_axis.append(0)\n",
    "                \n",
    "    return (np.asarray(all_major), np.asarray(all_minor), np.asarray(all_radii), all_paths,\n",
    "            avg_branch_radii, avg_branch_minor_axis, avg_branch_major_axis, all_directions_units\n",
    "            )\n",
    "\n",
    "def extract_2d_slice(segmentation_mask, boundary, point, direction_unit, radius=20):\n",
    "    D = np.dot(direction_unit, point)\n",
    "    min_point = np.maximum(point - radius, [0, 0, 0])\n",
    "    max_point = np.minimum(point + radius, segmentation_mask.shape)\n",
    "    \n",
    "    grid_x, grid_y, grid_z = np.meshgrid(\n",
    "        np.arange(min_point[0], max_point[0]),\n",
    "        np.arange(min_point[1], max_point[1]),\n",
    "        np.arange(min_point[2], max_point[2]),\n",
    "        indexing='ij')\n",
    "    \n",
    "    voxel_centers = np.column_stack((grid_x.ravel(), grid_y.ravel(), grid_z.ravel()))\n",
    "    distances = np.abs(np.dot(voxel_centers, direction_unit) - D)\n",
    "    plane = (distances < 0.5).reshape(grid_x.shape)\n",
    "    \n",
    "    out_mask = np.zeros(plane.shape)\n",
    "    out_mask = np.logical_and(plane, segmentation_mask[min_point[0]:max_point[0], min_point[1]:max_point[1], min_point[2]:max_point[2]])\n",
    "    \n",
    "    out_boundary = np.zeros(boundary.shape)\n",
    "    out_boundary = np.logical_and(plane, boundary[min_point[0]:max_point[0], min_point[1]:max_point[1], min_point[2]:max_point[2]])\n",
    "    \n",
    "    new_point = point * (min_point == 0) + radius * (min_point != 0)\n",
    "\n",
    "    return out_boundary, out_mask, new_point\n",
    "\n",
    "def compute_radii_aux(path, mask, boundary, direction_unit):\n",
    "    major_axes = []\n",
    "    minor_axes = []\n",
    "    radii = []\n",
    "    tam_ = np.shape(path)[0]\n",
    "    first_point = True\n",
    "    for p in range(int(tam_/2), tam_):\n",
    "\n",
    "        point = np.asarray(path[p])\n",
    "\n",
    "        aux_boundary, aux_mask, point = extract_2d_slice(mask, boundary, point, direction_unit)\n",
    "\n",
    "        aux_mask = label(aux_mask)\n",
    "        \n",
    "        l = aux_mask[point[0], point[1], point[2]]\n",
    "        \n",
    "        aux_boundary[aux_mask!=l] = 0\n",
    "        \n",
    "        indices_ = np.argwhere(aux_boundary) # get indices of the contour\n",
    "\n",
    "        if np.shape(indices_)[0]>0:\n",
    "\n",
    "            all_distances = np.sqrt(np.sum((indices_ - point)**2, axis=-1)) #Euclidean distance\n",
    "            #from the point to each point in the boundary\n",
    "\n",
    "            major_curr = np.max(all_distances)\n",
    "            minor_curr = np.min(all_distances)\n",
    "            \n",
    "            if first_point:\n",
    "                major_axes.append(major_curr)\n",
    "                minor_axes.append(minor_curr)\n",
    "                radii.append(np.mean(all_distances))\n",
    "                first_point = False\n",
    "            else:\n",
    "                delta_radius_major = np.abs(major_curr-major_axes[-1])\n",
    "                delta_radius_minor = np.abs(minor_curr-minor_axes[-1])\n",
    "                if delta_radius_major<4:\n",
    "                    major_axes.append(major_curr)\n",
    "                    minor_axes.append(minor_curr)\n",
    "                    radii.append(np.mean(all_distances))\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "    path = np.flip(path,0)\n",
    "    for p in range(int(tam_/2), tam_):\n",
    "\n",
    "        point = np.asarray(path[p])\n",
    "\n",
    "        aux_boundary, aux_mask, point = extract_2d_slice(mask, boundary, point, direction_unit)\n",
    "\n",
    "        aux_mask = label(aux_mask)\n",
    "        \n",
    "        l = aux_mask[point[0], point[1], point[2]]\n",
    "        \n",
    "        aux_boundary[aux_mask!=l] = 0\n",
    "        \n",
    "        indices_ = np.argwhere(aux_boundary) # get indices of the contour\n",
    "\n",
    "        if np.shape(indices_)[0]>0:\n",
    "\n",
    "            all_distances = np.sqrt(np.sum((indices_ - point)**2, axis=-1)) #Euclidean distance\n",
    "            #from the point to each point in the boundary\n",
    "            \n",
    "            major_curr = np.max(all_distances)\n",
    "            minor_curr = np.min(all_distances)\n",
    "            \n",
    "            if first_point:\n",
    "                major_axes.append(major_curr)\n",
    "                minor_axes.append(minor_curr)\n",
    "                radii.append(np.mean(all_distances))\n",
    "                first_point = False\n",
    "            else:\n",
    "                delta_radius_major = np.abs(major_curr-major_axes[-1])\n",
    "                delta_radius_minor = np.abs(minor_curr-minor_axes[-1])\n",
    "                if delta_radius_major<4:\n",
    "                    major_axes.append(major_curr)\n",
    "                    minor_axes.append(minor_curr)\n",
    "                    radii.append(np.mean(all_distances))\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    return major_axes, minor_axes, radii\n",
    "\n",
    "\n",
    "def skeleton_pruning(skeleton: Skeleton, spacing = [1,1,1]) -> Skeleton:\n",
    "    \"\"\"Prune a skeleton using recursion removing the specified branch type.\n",
    "    Parameters\n",
    "    ----------\n",
    "    remove_branch_type: int\n",
    "        Remove branches of the specified type options are the types returned under `branch-type` by summarize and\n",
    "    the default is `1` which removes junction-to-endpoint branches.\n",
    "          0 endpoint-to-endpoint (isolated branch)\n",
    "          1 junction-to-endpoint\n",
    "          2 juntciont-to-junction\n",
    "          3 isolated cycle\n",
    "    Returns\n",
    "    -------\n",
    "    Skeleton\n",
    "        Returns a new Skeleton instance.\n",
    "    \"\"\"\n",
    "\n",
    "    original = Skeleton(skeleton, spacing=spacing)\n",
    "    branch_data = summarize(original, separator='-')\n",
    "\n",
    "    print(f\"Before Pruning: {len(original.paths.indices)}\")\n",
    "\n",
    "    # pruned = pruned.prune_paths(branch_data.loc[(branch_data[\"branch-type\"] == 2) & (branch_data['branch-distance'] < 5.0)].index)\n",
    "    # branch_data = summarize(pruned, separator='-')\n",
    "\n",
    "    # print(f\"After Pruning: {len(pruned.paths.indices)}\")\n",
    "\n",
    "    pruned = original.prune_paths(branch_data.loc[branch_data[\"branch-type\"] == 3].index) # Pruning the loops\n",
    "    branch_data = summarize(pruned, separator='-')\n",
    "\n",
    "    print(f\"After Loop Pruning Iter1 : {len(pruned.paths.indices)}\")\n",
    "\n",
    "    pruned = pruned.prune_paths(branch_data.loc[branch_data[\"branch-type\"] == 3].index) # Pruning the loops\n",
    "    branch_data = summarize(pruned, separator='-')\n",
    "\n",
    "    print(f\"After Loop Pruning Iter2: {len(pruned.paths.indices)}\")\n",
    "\n",
    "    pruned = pruned.prune_paths(branch_data.loc[(branch_data[\"branch-type\"] == 0) & (branch_data['branch-distance'] < 12.0)].index)\n",
    "    branch_data = summarize(pruned, separator='-')\n",
    "\n",
    "    print(f\"After Isolated Branch Pruning: {len(pruned.paths.indices)}\")\n",
    "\n",
    "    pruned = pruned.prune_paths(branch_data.loc[(branch_data[\"branch-type\"] == 1) & (branch_data['branch-distance'] < 12.0)].index)\n",
    "    branch_data = summarize(pruned, separator='-')\n",
    "\n",
    "    print(f\"After Small Endpoint Pruning Iter1 : {len(pruned.paths.indices)}\")\n",
    "\n",
    "    pruned = pruned.prune_paths(branch_data.loc[(branch_data[\"branch-type\"] == 1) & (branch_data['branch-distance'] < 12.0)].index)\n",
    "    branch_data = summarize(pruned, separator='-')\n",
    "    print(f\"After Small Endpoint Pruning Iter2: {len(pruned.paths.indices)}\")\n",
    "\n",
    "\n",
    "    pruned = pruned.prune_paths(branch_data.loc[branch_data[\"branch-type\"] == 3].index) # Pruning the loops\n",
    "    branch_data = summarize(pruned, separator='-')\n",
    "\n",
    "    print(f\"After Loop Pruning Iter3: {len(pruned.paths.indices)}\")\n",
    "\n",
    "    pruned = Skeleton(pruned.skeleton_image, spacing=[1,1,1])\n",
    "\n",
    "    return pruned\n",
    "\n",
    "def extract_dapi_values_from_arrays(path_array, matrix):\n",
    "    values = []\n",
    "    for coord in path_array:\n",
    "        if len(coord) == 3:\n",
    "            x, y, z = coord[0], coord[1], coord[2]\n",
    "            if 0 <= x < matrix.shape[0] and 0 <= y < matrix.shape[1] and 0 <= z < matrix.shape[2]:\n",
    "                values.append(int(matrix[x, y, z]))\n",
    "    return values\n",
    "\n",
    "def get_corresponding_dapi_path(cell_result_path):\n",
    "    try:\n",
    "        # Convert to Path object for easier manipulation\n",
    "        path = Path(cell_result_path)\n",
    "        \n",
    "        # Get the series folder (parent of the results folder)\n",
    "        series_folder = path.parent\n",
    "        \n",
    "        # Construct the DAPI results path\n",
    "        dapi_path = series_folder / \"DAPI_results\"\n",
    "        \n",
    "        # Verify the DAPI path exists\n",
    "        if dapi_path.exists():\n",
    "            return str(dapi_path)\n",
    "        else:\n",
    "            print(f\"Warning: No DAPI_results folder found for {cell_result_path}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing path {cell_result_path}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "def calculate_branch_ratios(branch_data):\n",
    "    # Filter branches of type 1\n",
    "    type_1_branches = branch_data[branch_data['branch-type'] == 1]\n",
    "\n",
    "    # Initialize new columns for branch ratios with NaN\n",
    "    branch_data['Branch 1 Ratio'] = np.nan\n",
    "    branch_data['Branch 2 Ratio'] = np.nan\n",
    "    branch_data['Protrusion-Factor-1'] = np.nan\n",
    "    branch_data['Protrusion-Factor-2'] = np.nan\n",
    "\n",
    "\n",
    "    # Process only type 1 branches\n",
    "    for index, branch in type_1_branches.iterrows():\n",
    "        source_node = branch['node-id-src']\n",
    "        destination_node = branch['node-id-dst']\n",
    "        current_radius = branch['Radius']\n",
    "        current_eu_dist = branch['euclidean-distance']\n",
    "\n",
    "        # Find all related branches (excluding the current branch)\n",
    "        related_branches = branch_data[\n",
    "            ((branch_data['node-id-src'] == source_node) | (branch_data['node-id-dst'] == source_node) |\n",
    "             (branch_data['node-id-src'] == destination_node) | (branch_data['node-id-dst'] == destination_node)) &\n",
    "            (branch_data.index != index)\n",
    "        ]\n",
    "\n",
    "        # Sort and pick the first two branches\n",
    "        related_branches = related_branches.head(2)\n",
    "\n",
    "        # Calculate the ratios for the first two branches if they exist\n",
    "        if len(related_branches) > 0:\n",
    "            branch_1_radius = related_branches.iloc[0]['Radius']\n",
    "            branch_1_ratio = branch_1_radius / current_radius\n",
    "            protrusion_factor = branch_1_radius / current_eu_dist\n",
    "            branch_data.at[index, 'Branch-1-Ratio'] = branch_1_ratio\n",
    "            branch_data.at[index, 'Protrusion-Factor-1'] = protrusion_factor\n",
    "\n",
    "            if len(related_branches) > 1:\n",
    "                branch_2_radius = related_branches.iloc[1]['Radius']\n",
    "                branch_2_ratio = branch_2_radius / current_radius\n",
    "                protrusion_factor = branch_2_radius / current_eu_dist\n",
    "                branch_data.at[index, 'Branch-2-Ratio'] = branch_2_ratio        \n",
    "                branch_data.at[index, 'Protrusion-Factor-2'] = protrusion_factor\n",
    "\n",
    "    return branch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed7058-64e4-45a3-b95a-7ac9e691b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_branch_instance_mask(skeleton, mask, branch_data, paths_final):\n",
    "    \"\"\"\n",
    "    Creates instance segmentation using watershed from skeleton to vessel boundaries\n",
    "    \"\"\"\n",
    "    # Initialize seeds mask with unique labels for each branch\n",
    "    seeds = np.zeros_like(skeleton, dtype=np.uint16)\n",
    "    branch_to_label = {}\n",
    "    \n",
    "    # Create seeds for each branch\n",
    "    for idx, path in enumerate(paths_final, start=1):\n",
    "        if len(path) > 0:\n",
    "            path = np.array(path)\n",
    "            seeds[path[:, 0], path[:, 1], path[:, 2]] = idx\n",
    "            branch_to_label[idx-1] = idx\n",
    "    \n",
    "    # Calculate distance transform from vessel boundaries\n",
    "    # We invert the mask because distance_transform_edt works on background\n",
    "    dist = distance_transform_edt(mask)\n",
    "    \n",
    "    # Use watershed to grow regions from seeds\n",
    "    # The -dist means regions grow faster where they are further from boundaries\n",
    "    instance_mask = watershed(-dist, seeds, mask=mask)\n",
    "    \n",
    "    return instance_mask, branch_to_label\n",
    "\n",
    "def create_branch_points_mask(skeleton, branch_data, bpoints_id):\n",
    "    \"\"\"\n",
    "    Creates a mask highlighting branch points\n",
    "    \"\"\"\n",
    "    branch_points_mask = np.zeros_like(skeleton, dtype=np.uint8)\n",
    "    \n",
    "    for bp_id in bpoints_id:\n",
    "        branches_with_point = branch_data[\n",
    "            (branch_data['node-id-src'] == bp_id) | \n",
    "            (branch_data['node-id-dst'] == bp_id)\n",
    "        ].iloc[0]\n",
    "        \n",
    "        if branches_with_point['node-id-src'] == bp_id:\n",
    "            x = int(branches_with_point['image-coord-src-0'])\n",
    "            y = int(branches_with_point['image-coord-src-1'])\n",
    "            z = int(branches_with_point['image-coord-src-2'])\n",
    "        else:\n",
    "            x = int(branches_with_point['image-coord-dst-0'])\n",
    "            y = int(branches_with_point['image-coord-dst-1'])\n",
    "            z = int(branches_with_point['image-coord-dst-2'])\n",
    "        \n",
    "        # Just mark the point and its immediate neighbors\n",
    "        branch_points_mask[x, y, z] = 1\n",
    "    \n",
    "    return branch_points_mask\n",
    "\n",
    "def save_branch_visualization(skeleton, mask, branch_data, paths_final, outputdir, input_filename):\n",
    "    \"\"\"\n",
    "    Saves branch instance mask and branch point mask\n",
    "    \"\"\"\n",
    "    print(\"Creating branch instance mask...\")\n",
    "    branch_mask, branch_to_label = create_branch_instance_mask(skeleton, mask, branch_data, paths_final)\n",
    "    branch_mask = np.swapaxes(branch_mask, 0, 2)\n",
    "    \n",
    "    print(\"Creating branch points mask...\")\n",
    "    _, bpoints_id, _, _ = branching_points(branch_data)\n",
    "    branch_points_mask = create_branch_points_mask(skeleton, branch_data, bpoints_id)\n",
    "    branch_points_mask = np.swapaxes(branch_points_mask, 0, 2)\n",
    "    \n",
    "    print(f\"Saving visualizations to {outputdir}...\")\n",
    "    tifffile.imwrite(f'{outputdir}/{input_filename}_branch_labels_nnunet.tif', branch_mask)\n",
    "    tifffile.imwrite(f'{outputdir}/{input_filename}_branch_points_nnunet.tif', branch_points_mask)\n",
    "    print(\"Visualization files saved successfully!\")\n",
    "    \n",
    "    return branch_to_label\n",
    "\n",
    "def get_group_name(input_path):\n",
    "    \"\"\"\n",
    "    Extracts the group name from the input path\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the filepath into blocks using '/' as the delimiter\n",
    "    blocks = input_path.split('/')\n",
    "\n",
    "    # Find the block containing the word 'acquisition' (case-insensitive)\n",
    "    for block in blocks:\n",
    "        if 'acquisition' in block.lower():\n",
    "            group_name = block\n",
    "            break\n",
    "            \n",
    "    group_name = \"_\".join(group_name.split('_')[:-2])\n",
    "    return group_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd59f8-a179-4e2a-98e7-e4e9a4fcda14",
   "metadata": {},
   "source": [
    "## Get all valid isotropic Blood Vessel Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965208e7-d063-4f4a-93d6-66148b8c154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_icam2_paths(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process directories to find Icam2 images and create corresponding result folders.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Path to the input directory containing processed images\n",
    "        output_dir (str): Path to create DAPI results folders\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[str], List[str]]: Lists of (input DAPI paths, output result folder paths)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Initialize lists to store paths\n",
    "    icam2_paths = []\n",
    "    dapi_paths = []\n",
    "    icam2_result_paths = []\n",
    "    \n",
    "    # Convert to Path objects for easier handling\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "\n",
    "        \n",
    "        # Convert current root to Path object\n",
    "        root_path = Path(root)\n",
    "        \n",
    "        # Check if we're in an isotropic_image folder\n",
    "        if root_path.name == \"isotropic_image\":\n",
    "            file_name = \"C1-Icam2-Blood-Vessels.tif\"\n",
    "            # dapi_file_name = \"C4-DAPI-XZ.tif\"\n",
    "\n",
    "            # Look for C4-DAPI-XZ.tif in files\n",
    "            if file_name in files:\n",
    "                # Get the full path to the DAPI XZ image\n",
    "                full_path = root_path / file_name\n",
    "                # adpi_path = root_path / dapi_file_name\n",
    "                \n",
    "                # Get the series folder name (parent of isotropic_image)\n",
    "                series_folder = root_path.parent.name\n",
    "                \n",
    "                # Create corresponding output folder structure\n",
    "                result_folder = output_path / series_folder / \"ICAM2_results\"\n",
    "                result_folder.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # Add paths to lists\n",
    "                icam2_paths.append(str(full_path))\n",
    "                # dapi_path = root_path / dapi_file_name\n",
    "                icam2_result_paths.append(str(result_folder))\n",
    "                \n",
    "                print(f\"Found  ICAM2 image: {full_path}\")\n",
    "                # print(f\"Found DAPI image: {dapi_path}\")\n",
    "                print(f\"Created results folder: {result_folder}\")\n",
    "    \n",
    "    return icam2_paths, icam2_result_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d04db9-2aa9-4568-bbf3-fb3f508e7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_paths, result_paths = process_icam2_paths(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a99e25-6e8f-4b1e-b042-5bafda2bff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bv_input_file, result_output_directory in zip(bv_paths, result_paths):\n",
    "    print(f\"Executing Blood Vessel Pipeline for :{bv_input_file}\")\n",
    "    # File paths\n",
    "    input_file = bv_input_file\n",
    "    input_filename = os.path.basename(input_file).split('.')[0]\n",
    "    input_dir = os.path.dirname(input_file)\n",
    "    output_dir = result_output_directory\n",
    "\n",
    "    # Get DAPI Segmentation\n",
    "    DAPI_path_parent = get_corresponding_dapi_path(result_output_directory)\n",
    "    DAPI_path = os.path.join(DAPI_path_parent, \"C4-DAPI-XZ_reconstructed_cleaned_xy.tif\")\n",
    "    print(f\"Dapi Path found: {DAPI_path}\")\n",
    "    dapi = tifffile.imread(DAPI_path)\n",
    "    dapi = np.swapaxes(dapi, 0, 2)\n",
    "\n",
    "    # Change here - when changing the input name of the segmentation output\n",
    "    msk_name = f'{input_filename}_nnunet_reconstructed_cleaned_filtered.tif'\n",
    "\n",
    "    # Default values for the other columns - CHANGE THIS WHEN THE ISOTROPIC/NON-ISOTROPIC\n",
    "    default_values = {\n",
    "        \"resx\": 1,\n",
    "        \"resy\": 1,\n",
    "        \"resz\": 1,\n",
    "    }\n",
    "\n",
    "   \n",
    "    ellipsoid = draw.ellipsoid(3,3,2, spacing=(1,1,1), levelset=False)\n",
    "    ellipsoid = ellipsoid.astype('uint8')\n",
    "    ellipsoid = ellipsoid[1:-1,1:-1,1:-1]\n",
    "\n",
    "    vessel_features = pd.DataFrame(columns=('Image', 'Group', 'Branching Points Density', \n",
    "                                    'Mean Branch Length', 'Mean Vessel Radius', 'Mean Minor Axis Length',\n",
    "                                    'Mean Major Axis Length'))\n",
    "\n",
    "    print('Mask Name: {}'.format(msk_name))\n",
    "\n",
    "    #get the resolution information\n",
    "    dimx = default_values[\"resx\"] \n",
    "    dimy = default_values[\"resy\"]\n",
    "    dimz = default_values[\"resz\"]\n",
    "    print('dimensions: {} {} {}'.format(dimx, dimy, dimz))\n",
    "\n",
    "    #mask and region of interest (ROI)\n",
    "    print(\"here\",os.path.join(output_dir, msk_name))\n",
    "    mask = tifffile.imread(os.path.join(output_dir, msk_name)) # To be tested\n",
    "    mask[mask!=0] = 1\n",
    "    mask = mask.astype('uint8')\n",
    "    mask = np.swapaxes(mask, 0, 2)\n",
    "    print('Mask Shape: {}'.format(np.shape(mask)))\n",
    "\n",
    "    \n",
    "    mask_roi = (mask*1).astype('uint8')\n",
    "    print('skeletonization')\n",
    "    skeleton = skeletonize(mask_roi)\n",
    "    skeleton = skeleton.astype('uint8')\n",
    "\n",
    "    #compute the vascular density and avascular area\n",
    "    total_area = len(mask) #total area of the ROI\n",
    "    # vasc_dens = (len(mask[mask==1]) / (total_area) ) * 100 #vascular density\n",
    "    # avas_area = (len(mask[mask==0]) / (total_area) ) * 100 #avascular area\n",
    "\n",
    "    #Adding Skeleton Cleaning \n",
    "    pruned_skeleton = skeleton_pruning(skeleton, spacing=[1,1,1])\n",
    "    branch_data = summarize(pruned_skeleton,separator='-')\n",
    "    bpoints, bids, epoints, eids = branching_points(branch_data)\n",
    "\n",
    "    print('Skeletons Features Computed')\n",
    "    mask = (mask*1).astype('uint8')\n",
    "\n",
    "    ellipsoid = draw.ellipsoid(1,1,1, spacing=(1,1,1), levelset=False)\n",
    "    ellipsoid = ellipsoid.astype('uint8')\n",
    "    er = binary_erosion(mask, ellipsoid)\n",
    "    boundaries = mask - er\n",
    "\n",
    "    radius_func_results = radius_3d_main(pruned_skeleton.skeleton_image, branch_data, mask, boundaries)\n",
    "    major_axes_final = radius_func_results[0]\n",
    "    minor_axes_final = radius_func_results[1]\n",
    "    radii_final = radius_func_results[2]\n",
    "    paths_final = radius_func_results[3]\n",
    "    branch_radii = radius_func_results[4]\n",
    "    branch_minor_axis = radius_func_results[5]\n",
    "    branch_major_axis = radius_func_results[6]\n",
    "    direction_unit = radius_func_results[7]\n",
    "\n",
    "    branch_data[\"Radius\"] = branch_radii\n",
    "    branch_data[\"Minor-Axis\"] = branch_minor_axis\n",
    "    branch_data[\"Major-Axis\"] = branch_major_axis\n",
    "\n",
    "    branch_data['Direction-Unit'] = direction_unit\n",
    "    branch_data['Direction-Unit-X'] = branch_data['Direction-Unit'].apply(lambda x: x[0].item())\n",
    "    branch_data['Direction-Unit-Y'] = branch_data['Direction-Unit'].apply(lambda x: x[1].item())\n",
    "    branch_data['Direction-Unit-Z'] = branch_data['Direction-Unit'].apply(lambda x: x[2].item())\n",
    "    branch_data = branch_data.drop(columns=['Direction-Unit'])\n",
    "    \n",
    "    print(\"Saving branch viz\")\n",
    "    branch_to_label = save_branch_visualization(pruned_skeleton, mask, branch_data, paths_final, output_dir, input_filename)\n",
    "    \n",
    "    # Add the branch label IDs to branch_data before saving\n",
    "    branch_data['Branch-Label-ID'] = branch_data.index.map(lambda x: branch_to_label.get(x, -1))\n",
    "    branch_data = calculate_branch_ratios(branch_data)\n",
    "\n",
    "    #Saving the numpy arrays\n",
    "    np.save(f'{output_dir}/{input_filename}_major_axes_nnunet.npy', major_axes_final)\n",
    "    np.save(f'{output_dir}/{input_filename}_minor_axes_nnunet.npy', minor_axes_final)\n",
    "    np.save(f'{output_dir}/{input_filename}_radii_nnunet.npy', radii_final)\n",
    "\n",
    "    # Store results in a DataFrame for the current mask\n",
    "    vessel_features = pd.DataFrame({\n",
    "        'Image': [msk_name],\n",
    "        'Group': get_group_name(input_file),\n",
    "        'Branching-Points-Density': [bpoints / total_area],\n",
    "        'Mean-Branch-Length': [branch_data['branch-distance'].mean()],\n",
    "        'Mean-Vessel-Radius': [np.mean(radii_final)],\n",
    "        'Mean-Minor-Axis-Length': [np.mean(minor_axes_final)],\n",
    "        'Mean-Major-Axis-Length': [np.mean(major_axes_final)]\n",
    "    })\n",
    "\n",
    "    # Create csv file with image name and features\n",
    "    result_file = f'{output_dir}/{input_filename}_features_nnunet.csv'\n",
    "    skeleton_result_file = f'{output_dir}/{input_filename}_skeleton_features_nnunet.csv'\n",
    "\n",
    "    vessel_features.to_csv(result_file, sep=',', index=False)\n",
    "    print(f\"Saved sample feature statistics csv for {msk_name} to {result_file}\")\n",
    "\n",
    "    branch_data['Tortuosity-Index'] = (branch_data['branch-distance'] - branch_data['euclidean-distance']) / branch_data['branch-distance']\n",
    "    branch_data['Path'] = paths_final\n",
    "    branch_data['No-of-paths'] = (\n",
    "        branch_data.groupby(['node-id-src', 'node-id-dst'])['branch-distance']\n",
    "        .rank(method='dense', ascending=True).astype(int)\n",
    "    )\n",
    "    branch_data['DAPI-Values'] = branch_data['Path'].apply(lambda path_array: extract_dapi_values_from_arrays(path_array, dapi))\n",
    "    branch_data['Dapi'] = branch_data['DAPI-Values'].apply(\n",
    "        lambda values: max(set(values), key=values.count) if values else None\n",
    "    )\n",
    "    branch_data = branch_data.drop(columns=['DAPI-Values'])\n",
    "    branch_data = branch_data.drop(columns=['Path'])\n",
    "\n",
    "    branch_data.to_csv(skeleton_result_file, sep=',', index=False)\n",
    "    print(f\"Saved Skeleton branch results for {msk_name} to {skeleton_result_file}\")\n",
    "    \n",
    "    all_paths = [pruned_skeleton.path_coordinates(i) for i in range(pruned_skeleton.n_paths)]\n",
    "    result_file_all_paths = f'{output_dir}/{input_filename}_all_paths_nnunet.pkl'\n",
    "    pickle.dump(all_paths, open(result_file_all_paths, 'wb'))\n",
    "    print(f\"Saved Path array for {msk_name} to {result_file_all_paths}\")\n",
    "    \n",
    "print(\"Processing complete !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fcb33-b9f7-4920-95a3-920d5d9564e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
